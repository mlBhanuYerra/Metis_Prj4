{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-09T23:31:14.262122Z",
     "start_time": "2019-11-09T23:31:14.259333Z"
    }
   },
   "source": [
    "### Amazon Cookbooks Topic-modeling: Create Categories and Scarpe for Pics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T14:44:56.264291Z",
     "start_time": "2019-11-10T14:44:56.243523Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re, string\n",
    "import os, glob, re\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "\n",
    "#import contractions\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from langdetect import detect\n",
    "from textblob import TextBlob\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA, LatentDirichletAllocation, TruncatedSVD, NMF\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input as vgg16_ppi\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.vgg19 import preprocess_input as vgg19_ppi\n",
    "from keras.applications.resnet_v2 import ResNet50V2\n",
    "from keras.applications.resnet_v2 import preprocess_input as Res50V2_ppi\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.inception_v3 import preprocess_input as inceptv3_ppi\n",
    "from keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from keras.applications.mobilenet_v2 import preprocess_input as moblv2_ppi\n",
    "\n",
    "from joblib import dump, load\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "%matplotlib inline\n",
    "\n",
    "    \n",
    "# --- Parser for reading in the Amazon json files (can be used for both reviews and metadata)\n",
    "# --- credits folloing parse() method to Julian McAuley UCSD: http://jmcauley.ucsd.edu/data/amazon/ \n",
    "def parse(path):\n",
    "    g = open(path, 'r')\n",
    "    for l in g:\n",
    "        yield json.loads(l)\n",
    "        \n",
    "PRETRAINED_MODELS = {\n",
    "    'VGG16': {\n",
    "        'model': VGG16,\n",
    "        'preprocess': vgg16_ppi,\n",
    "        'shape': (224, 224)\n",
    "    },\n",
    "    'VGG19': {\n",
    "        'model': VGG19,\n",
    "        'preprocess': vgg19_ppi,\n",
    "        'shape': (224, 224)\n",
    "    },\n",
    "    'ResNet50V2': {\n",
    "        'model': ResNet50V2,\n",
    "        'preprocess': Res50V2_ppi,\n",
    "        'shape': (224, 224)\n",
    "    },\n",
    "    'InceptionV3': {\n",
    "        'model': InceptionV3,\n",
    "        'preprocess': inceptv3_ppi,\n",
    "        'shape': (299, 299)\n",
    "    },\n",
    "    'MobileNetV2': {\n",
    "        'model': MobileNetV2,\n",
    "        'preprocess': moblv2_ppi,\n",
    "        'shape': (224, 224)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class amazonCookbookCovers:\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, loc=\"../data/amzn/covers/\"):\n",
    "        \n",
    "        self.cookbook_covers_location = loc\n",
    "        self.getASINs()\n",
    "        \n",
    "        # --- for future\n",
    "        #  Code to check if the 'loc' is a valid dataset\n",
    "        #  if not, download data and unzip\n",
    "        #  same for the labels matlab file\n",
    "    \n",
    "    def getASINs(self):\n",
    "        self.asins_with_covers = [f for f in os.listdir(self.cookbook_covers_location) if os.path.isfile(os.path.join(self.cookbook_covers_location, f)) and \".jpg\" in f]\n",
    "    \n",
    "    def getNextCover(self):\n",
    "        #count = len(self.asins_with_covers)\n",
    "        for f in self.asins_with_covers:\n",
    "            print(f)\n",
    "            yield f\n",
    "            \n",
    "    def getNextNCovers(self, limit):\n",
    "        count = 0\n",
    "        Nimages = []\n",
    "        for f in self.asins_with_covers:\n",
    "            if count%limit==0 and count!=0:\n",
    "                yield Nimages\n",
    "                count = 0\n",
    "                Nimages = []\n",
    "            else:\n",
    "                Nimages.append(f)\n",
    "                count += 1\n",
    "        yield Nimages #for the last bunch that might be less than limit\n",
    "        \n",
    "        \n",
    "    def getOneImageArray(self, fileName, target_size=(224, 224)):\n",
    "        img_path =  self.cookbook_covers_location + fileName\n",
    "        img = image.load_img(img_path, target_size=target_size)\n",
    "        x = image.img_to_array(img)\n",
    "        #x = np.expand_dims(x, axis=0)\n",
    "        \n",
    "        return x\n",
    "       \n",
    "    def getNextNImageArrays(self, limit=20, target_size=(224, 224) ):\n",
    "        count = 0\n",
    "        NimageArrays = []\n",
    "        for f in self.asins_with_covers:\n",
    "            if count%limit==0 and count!=0:\n",
    "                yield np.array(NimageArrays)\n",
    "                count = 0\n",
    "                NimageArrays = []\n",
    "            else:\n",
    "                NimageArrays.append(self.getOneImageArray(f, target_size=target_size))\n",
    "                count += 1\n",
    "        yield np.array(NimageArrays) #for the last bunch that might be less than limit\n",
    "\n",
    "amzn_cvrs = amazonCookbookCovers()\n",
    "#print(amzn_cvrs.getNImageArrays(limit=20, target_size=(299, 299)).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[109. 112. 121.]\n",
      "   [112. 133. 136.]\n",
      "   [ 86. 133. 127.]\n",
      "   ...\n",
      "   [109. 124. 121.]\n",
      "   [105. 115. 114.]\n",
      "   [119. 125. 125.]]\n",
      "\n",
      "  [[ 81. 138. 131.]\n",
      "   [ 99. 175. 162.]\n",
      "   [ 87. 191. 168.]\n",
      "   ...\n",
      "   [ 40.  56.  53.]\n",
      "   [ 44.  56.  52.]\n",
      "   [104. 115. 111.]]\n",
      "\n",
      "  [[ 77. 138. 130.]\n",
      "   [ 81. 164. 148.]\n",
      "   [ 74. 182. 159.]\n",
      "   ...\n",
      "   [ 34.  53.  47.]\n",
      "   [ 30.  45.  40.]\n",
      "   [108. 120. 116.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[107. 126. 120.]\n",
      "   [ 27.  48.  43.]\n",
      "   [ 25.  47.  44.]\n",
      "   ...\n",
      "   [ 19.  28.  27.]\n",
      "   [ 26.  35.  32.]\n",
      "   [107. 116. 113.]]\n",
      "\n",
      "  [[109. 121. 117.]\n",
      "   [ 32.  47.  44.]\n",
      "   [ 31.  47.  46.]\n",
      "   ...\n",
      "   [ 14.  20.  20.]\n",
      "   [ 23.  32.  29.]\n",
      "   [112. 121. 118.]]\n",
      "\n",
      "  [[128. 134. 134.]\n",
      "   [100. 106. 106.]\n",
      "   [110. 116. 116.]\n",
      "   ...\n",
      "   [112. 116. 115.]\n",
      "   [104. 110. 108.]\n",
      "   [125. 134. 131.]]]\n",
      "\n",
      "\n",
      " [[[ 93.  88.  92.]\n",
      "   [ 86.  81.  85.]\n",
      "   [ 78.  73.  77.]\n",
      "   ...\n",
      "   [ 56.  68.  80.]\n",
      "   [ 57.  69.  81.]\n",
      "   [ 52.  64.  76.]]\n",
      "\n",
      "  [[ 69.  64.  68.]\n",
      "   [ 71.  66.  70.]\n",
      "   [ 73.  68.  74.]\n",
      "   ...\n",
      "   [ 52.  64.  76.]\n",
      "   [ 51.  63.  75.]\n",
      "   [ 47.  59.  71.]]\n",
      "\n",
      "  [[ 75.  70.  76.]\n",
      "   [ 74.  69.  75.]\n",
      "   [ 71.  69.  74.]\n",
      "   ...\n",
      "   [ 52.  64.  76.]\n",
      "   [ 51.  63.  75.]\n",
      "   [ 47.  59.  71.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 84. 101. 131.]\n",
      "   [ 73.  88. 117.]\n",
      "   [ 72.  86. 113.]\n",
      "   ...\n",
      "   [ 66.  92. 119.]\n",
      "   [ 74. 100. 125.]\n",
      "   [ 72.  98. 123.]]\n",
      "\n",
      "  [[ 78.  95. 123.]\n",
      "   [ 77.  92. 121.]\n",
      "   [ 76.  90. 117.]\n",
      "   ...\n",
      "   [ 72.  98. 125.]\n",
      "   [ 85. 111. 136.]\n",
      "   [ 67.  91. 117.]]\n",
      "\n",
      "  [[ 95. 112. 142.]\n",
      "   [ 84.  99. 128.]\n",
      "   [ 72.  86. 113.]\n",
      "   ...\n",
      "   [ 46.  72.  97.]\n",
      "   [ 58.  82. 108.]\n",
      "   [ 61.  85. 109.]]]\n",
      "\n",
      "\n",
      " [[[ 74.  63.  67.]\n",
      "   [ 74.  63.  67.]\n",
      "   [ 74.  63.  67.]\n",
      "   ...\n",
      "   [254. 252. 253.]\n",
      "   [254. 252. 253.]\n",
      "   [254. 252. 253.]]\n",
      "\n",
      "  [[ 74.  63.  67.]\n",
      "   [ 74.  63.  67.]\n",
      "   [ 74.  63.  67.]\n",
      "   ...\n",
      "   [254. 252. 253.]\n",
      "   [254. 252. 253.]\n",
      "   [254. 252. 253.]]\n",
      "\n",
      "  [[ 56.  50.  52.]\n",
      "   [ 56.  50.  52.]\n",
      "   [ 56.  50.  52.]\n",
      "   ...\n",
      "   [252. 250. 251.]\n",
      "   [252. 250. 251.]\n",
      "   [252. 250. 251.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 59.  55.  20.]\n",
      "   [ 59.  55.  20.]\n",
      "   [ 59.  55.  20.]\n",
      "   ...\n",
      "   [141. 129. 115.]\n",
      "   [141. 129. 115.]\n",
      "   [141. 129. 115.]]\n",
      "\n",
      "  [[ 62.  59.  18.]\n",
      "   [ 62.  59.  18.]\n",
      "   [ 62.  59.  18.]\n",
      "   ...\n",
      "   [ 71.  62.  45.]\n",
      "   [ 71.  62.  45.]\n",
      "   [ 71.  62.  45.]]\n",
      "\n",
      "  [[ 62.  59.  18.]\n",
      "   [ 62.  59.  18.]\n",
      "   [ 62.  59.  18.]\n",
      "   ...\n",
      "   [ 71.  62.  45.]\n",
      "   [ 71.  62.  45.]\n",
      "   [ 71.  62.  45.]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[235. 223. 147.]\n",
      "   [250. 238. 162.]\n",
      "   [255. 244. 170.]\n",
      "   ...\n",
      "   [238. 234. 160.]\n",
      "   [239. 235. 161.]\n",
      "   [233. 229. 155.]]\n",
      "\n",
      "  [[248. 236. 160.]\n",
      "   [247. 235. 159.]\n",
      "   [255. 249. 174.]\n",
      "   ...\n",
      "   [253. 249. 175.]\n",
      "   [254. 250. 176.]\n",
      "   [252. 248. 174.]]\n",
      "\n",
      "  [[246. 234. 158.]\n",
      "   [245. 236. 159.]\n",
      "   [255. 247. 172.]\n",
      "   ...\n",
      "   [253. 249. 175.]\n",
      "   [254. 250. 176.]\n",
      "   [255. 251. 177.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[251. 250. 196.]\n",
      "   [252. 251. 195.]\n",
      "   [252. 251. 194.]\n",
      "   ...\n",
      "   [251. 236. 133.]\n",
      "   [241. 225. 127.]\n",
      "   [253. 238. 145.]]\n",
      "\n",
      "  [[255. 253. 202.]\n",
      "   [249. 248. 194.]\n",
      "   [255. 255. 199.]\n",
      "   ...\n",
      "   [248. 231. 125.]\n",
      "   [247. 232. 131.]\n",
      "   [251. 235. 140.]]\n",
      "\n",
      "  [[254. 254. 204.]\n",
      "   [248. 248. 196.]\n",
      "   [255. 255. 201.]\n",
      "   ...\n",
      "   [250. 232. 122.]\n",
      "   [250. 233. 129.]\n",
      "   [254. 238. 142.]]]\n",
      "\n",
      "\n",
      " [[[136.   0.   0.]\n",
      "   [136.   0.   0.]\n",
      "   [136.   0.   0.]\n",
      "   ...\n",
      "   [149.   0.   4.]\n",
      "   [149.   0.   4.]\n",
      "   [149.   0.   4.]]\n",
      "\n",
      "  [[136.   0.   0.]\n",
      "   [136.   0.   0.]\n",
      "   [136.   0.   0.]\n",
      "   ...\n",
      "   [149.   0.   4.]\n",
      "   [149.   0.   4.]\n",
      "   [149.   0.   4.]]\n",
      "\n",
      "  [[136.   0.   0.]\n",
      "   [136.   0.   0.]\n",
      "   [136.   0.   0.]\n",
      "   ...\n",
      "   [149.   0.   4.]\n",
      "   [149.   0.   4.]\n",
      "   [149.   0.   4.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[136.   0.   0.]\n",
      "   [136.   0.   0.]\n",
      "   [136.   0.   0.]\n",
      "   ...\n",
      "   [160.   0.   7.]\n",
      "   [161.   0.   8.]\n",
      "   [161.   0.   8.]]\n",
      "\n",
      "  [[136.   0.   0.]\n",
      "   [136.   0.   0.]\n",
      "   [136.   0.   0.]\n",
      "   ...\n",
      "   [161.   0.   8.]\n",
      "   [163.   0.   8.]\n",
      "   [163.   0.   8.]]\n",
      "\n",
      "  [[136.   0.   0.]\n",
      "   [136.   0.   0.]\n",
      "   [136.   0.   0.]\n",
      "   ...\n",
      "   [163.   0.   8.]\n",
      "   [163.   0.   8.]\n",
      "   [163.   0.   8.]]]\n",
      "\n",
      "\n",
      " [[[153. 121.  62.]\n",
      "   [180. 151.  93.]\n",
      "   [191. 169. 112.]\n",
      "   ...\n",
      "   [  4.   0.   1.]\n",
      "   [  6.   2.   3.]\n",
      "   [  7.   3.   4.]]\n",
      "\n",
      "  [[175. 146.  90.]\n",
      "   [195. 173. 116.]\n",
      "   [205. 185. 132.]\n",
      "   ...\n",
      "   [  2.   0.   1.]\n",
      "   [  1.   0.   0.]\n",
      "   [  1.   0.   0.]]\n",
      "\n",
      "  [[182. 157. 103.]\n",
      "   [201. 181. 128.]\n",
      "   [209. 193. 141.]\n",
      "   ...\n",
      "   [  2.   0.   1.]\n",
      "   [  1.   0.   0.]\n",
      "   [  2.   0.   1.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 90.  71.  15.]\n",
      "   [ 84.  65.   7.]\n",
      "   [ 85.  66.   8.]\n",
      "   ...\n",
      "   [  0.   0.   0.]\n",
      "   [  0.   0.   0.]\n",
      "   [  0.   0.   0.]]\n",
      "\n",
      "  [[ 94.  75.  19.]\n",
      "   [ 96.  77.  21.]\n",
      "   [ 94.  75.  19.]\n",
      "   ...\n",
      "   [  0.   0.   0.]\n",
      "   [  0.   0.   0.]\n",
      "   [  0.   0.   0.]]\n",
      "\n",
      "  [[108.  88.  37.]\n",
      "   [101.  81.  30.]\n",
      "   [ 95.  75.  24.]\n",
      "   ...\n",
      "   [  0.   0.   0.]\n",
      "   [  0.   0.   0.]\n",
      "   [  0.   0.   0.]]]]\n"
     ]
    }
   ],
   "source": [
    "a = amazonCookbookCovers().getNextNImageArrays(10,target_size=(299, 299))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metis] *",
   "language": "python",
   "name": "conda-env-metis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
